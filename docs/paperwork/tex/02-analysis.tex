\chapter{Аналитическая часть}

\section{Компилятор}

\textbf{Компилятор} \cite{compiler} -- это специальная программа, которая выполняет преобразование исходного кода, написанного на высокоуровневом языке программирования, в машинный код или другой низкоуровневый формат, понятный компьютеру. Высокоуровневые языки программирования, такие как C, C++, Java, Python, и другие, позволяют разработчикам описывать логику программ, используя удобные для человека конструкции: переменные, циклы, функции, классы и другие абстрактные структуры. Однако компьютеры не могут напрямую понимать эти конструкции, так как процессоры работают исключительно с низкоуровневыми инструкциями -- машинным кодом.

\textbf{Машинный код} \cite{machine-code} -- это набор двоичных инструкций, которые выполняются процессором компьютера. Каждая команда машинного кода задает конкретную операцию, такую как сложение двух чисел, перемещение данных между памятью и регистрами или условный переход. Например, операция сложения двух чисел в машинном коде может выглядеть как последовательность битов <<\texttt{10001001}>>, где каждая часть инструкции определяет операнд, команду и другие параметры.

Компилятор выполняет важнейшую роль в этом процессе, преобразуя исходный код программы (который понятен программисту) в инструкции, понятные процессору. Таким образом, он решает задачу связи между уровнем абстракции, на котором работает разработчик, и физической машиной, которая исполняет программу. Компилятор обеспечивает возможность программировать на высокоуровневом языке, не заботясь о конкретной архитектуре процессора, операционной системе или особенностях работы с памятью.

Одним из ключевых преимуществ компиляторов является то, что они обеспечивают возможность писать программы, которые могут выполняться на различных аппаратных платформах, не требуя от программиста детального знания о том, как работает каждая из этих платформ. Например, программа, написанная на C, может быть скомпилирована для процессора Intel, ARM или любой другой архитектуры, если для этих архитектур существуют соответствующие компиляторы. Этот процесс называется кросс-компиляцией — компилятор может производить код для целевой архитектуры, отличной от той, на которой он исполняется.


\section{Компиляция}

Компиляция состоит из нескольких этапов, каждый из которых выполняет важную функцию в процессе преобразования исходного кода в машинный код. Основные этапы содеражт следующее.

\begin{enumerate}
  \item Лексический анализ.
  \item Синтаксический анализ.
  \item Семантический анализ.
  \item Генерация машинного кода.
\end{enumerate}


\subsection{Лексический анализ}

\textbf{Лексический анализ} \cite{lex-analyzer} -- это первый этап компиляции, на котором исходный код программы разбивается на минимальные значимые элементы, называемые лексемами.

Важным понятием является понятие токена -- это объект, состоящий из двух частей: типа токена, который описывает, что это за лексема (например, "ключевое слово", "оператор", "идентификатор"), и значения токена, которое представляет саму лексему (например, "int" или "10").

Основная задача этого этапа -- преобразовать текст программы в структурированную последовательность токенов, которые затем будут переданы на следующие этапы компиляции (синтаксический и семантический анализы). Лексический анализатор устраняет ненужные элементы, такие как пробелы и комментарии, и выделяет базовые компоненты программы, такие как ключевые слова, операторы, идентификаторы и литералы.

Лексический анализатор обрабатывает исходный код программы как поток символов. Он читает исходный текст по символам, начиная с первого, и создает токены, объединяя символы в осмысленные группы. Этот процесс продолжается до тех пор, пока весь исходный код не будет обработан.

Рассмотрим основные задачи лексического анализа.

\begin{enumerate}
  \item \textbf{азбиение исходного кода на лексемы} -- исходный код анализируется и делится на последовательности символов, которые представляют собой токены.
  \item \textbf{Идентификация типов лексем} -— лексер классифицирует найденные лексемы на основе правил грамматики языка. Например, определяет, является ли последовательность символов ключевым словом, идентификатором или оператором.
  \item \textbf{Удаление незначащих символов} -— такие символы, как пробелы, табуляции и комментарии, игнорируются, поскольку они не влияют на выполнение программы, но могут присутствовать для улучшения читаемости кода.
  \item \textbf{Обработка ошибок на уровне лексем} -— лексер может обнаруживать ошибки, связанные с неправильным использованием символов или идентификаторов. Например, использование символов, которые недопустимы в идентификаторах, или отсутствие закрывающей кавычки в строковом литерале.
\end{enumerate}


\subsection{Синтаксический анализ}

\textbf{Синтаксический анализ} \cite{syntax-analyzer} -- это второй этап компиляции, следующий за лексическим анализом. Его основная цель -- проверить грамматическую правильность исходного кода и построить синтаксическое дерево (дерево разбора), представляющее структуру программы. В отличие от лексического анализа, который работает с отдельными лексемами, синтаксический анализ рассматривает отношения между ними и проверяет, соответствуют ли они правилам грамматики языка программирования.

Синтаксический анализатор можно представить как машину, которая берет на вход последовательность токенов и проверяет их на соответствие грамматическим правилам языка программирования. Если код соответствует правилам, то строится синтаксическое дерево. Если обнаруживается ошибка, то синтаксический анализатор сообщает об ошибке.

Рассмотрим основные задачи синтаксического анализа.
\begin{enumerate}
  \item \textbf{Проверка соответствия грамматике} -- синтаксический анализатор проверяет, соответствует ли последовательность токенов правилам грамматики языка программирования. Это позволяет обнаружить синтаксические ошибки, такие как некорректные выражения или отсутствие обязательных символов (например, закрывающих скобок или точек с запятой).
  \item \textbf{Построение синтаксического дерева} -- синтаксический анализатор строит древовидную структуру, которая отражает иерархические отношения между элементами программы. Узлы дерева представляют синтаксические конструкции, такие как выражения, операторы, блоки кода и т. д.
  \item \textbf{Подготовка к семантическому анализу} -- синтаксическое дерево служит основой для следующего этапа компиляции, на котором проверяется семантическая корректность программы.
\end{enumerate}


Синтаксический анализатор основывается на формальной грамматике, которая описывает правила структуры языка программирования. В теории формальных языков часто используется классификация грамматик по иерархии Хомского, которая включает следующие виды.

\begin{enumerate}
  \item \textbf{Контекстно-свободные грамматики} -- они определяют правила, по которым можно составлять выражения и операторы. Такие грамматики описываются в виде множества правил, где каждая левая часть правила может быть заменена на правую часть. Контекстно-свободные грамматики часто используются для описания синтаксиса языков программирования.
  \item \textbf{Контекстно-зависимые грамматики} -- в этих грамматиках правила зависят от контекста, в котором они применяются. Такие грамматики редко используются для описания синтаксиса языков программирования, но могут быть полезны для семантического анализа.
\end{enumerate}


\subsection{Семантический анализ}

\textbf{Семантический анализ} \cite{semantic-analyzer} -- это третий этап компиляции, следующий за синтаксическим анализом. Его основная цель — проверить, правильно ли программа использует смысловые (семантические) правила языка программирования. В то время как синтаксический анализ проверяет правильность структуры программы (правильность расстановки ключевых слов, операторов и т.д.), семантический анализ проверяет логику и осмысленность программы.

Рассмотрим основные задачи семантического анализа.
\begin{enumerate}
  \item \textbf{Проверка типов данных} -- определение того, соответствуют ли операнды и выражения типам, которые допустимы в данном контексте. Например, нельзя складывать строку и число, или присваивать дробное значение переменной целого типа.
  \item \textbf{Проверка объявлений переменных и функций} -- семантический анализатор проверяет, были ли все переменные и функции объявлены перед их использованием. Если переменная используется до объявления или вовсе не объявлена, будет выдана ошибка.
  \item \textbf{Проверка области видимости (скопа)} -- важно убедиться, что переменные и функции используются в правильной области видимости. Переменная, объявленная внутри функции, не должна быть доступна за её пределами, если она не была передана явно.
  \item \textbf{Проверка логики программы} -- например, семантический анализатор может обнаружить недопустимые конструкции, такие как деление на ноль, использование недоступных или освобождённых ресурсов, бесконечные циклы без выхода.
  \item \textbf{Вывод типов (type inference)} -— в некоторых языках, таких как Haskell или Python, компилятор может автоматически выводить типы переменных на основе контекста, в котором они используются.
  \item \textbf{Проверка корректности вызовов функций} -— например, семантический анализатор проверяет, что функции вызываются с правильным числом и типом аргументов.
\end{enumerate}


\subsection{Генерация машинного кода}

\textbf{Генерация машинного кода} \cite{code-generation} -- это один из заключительных этапов компиляции, на котором исходный код преобразуется в машинный код или промежуточный код, который может быть выполнен на целевой аппаратной платформе. Этот этап следуют после семантического анализа, где уже проверено, что программа логически и синтаксически корректна. Генерация кода включает в себя преобразование высокоуровневых абстракций в инструкции, которые могут быть непосредственно исполнены процессором или виртуальной машиной.

Рассмотрим основные задачи генерации кода.
\begin{enumerate}
  \item Преобразование промежуточного представления в машинный код -- на этом этапе промежуточное представление программы (например, в виде трехадресных инструкций или промежуточного языка) преобразуется в машинный код, который может быть исполнен процессором.
  \item Оптимизация кода -- генерируемый код может быть дополнительно оптимизирован для повышения его эффективности. Оптимизация может включать улучшение скорости выполнения, уменьшение размера кода или снижение потребления ресурсов.
  \item Генерация кода для различных платформ -- если компилятор поддерживает кросс-компиляцию, он должен сгенерировать код, который будет работать на различных аппаратных платформах.
\end{enumerate}


\section{ANTLR4}

\textbf{ANTLR} (ANother Tool for Language Recognition) \cite{antlr4} -- это мощный инструмент для создания парсеров и лексеров, используемый для работы с языками программирования, скриптовыми языками и любыми другими текстовыми форматами. ANTLR4 — это четвёртая версия ANTLR, которая улучшает и расширяет возможности предыдущих версий. Он используется для генерации парсеров, которые могут обрабатывать текстовые данные и преобразовывать их в структуры, понятные компьютеру.

Основные компоненты ANTLR4.


\begin{enumerate}
  \item Грамматика (Grammar):
  \begin{enumerate}
    \item Лексическая грамматика (Lexer grammar): определяет, как исходный текст разбивается на токены. Токены — это основные единицы текста, такие как ключевые слова, идентификаторы, операторы и литералы.
    \item Синтаксическая грамматика (Parser grammar): определяет, как токены должны быть организованы в более сложные структуры, такие как выражения и операторы. Это описывает структуру языка.
  \end{enumerate}

  \item Лексер (Lexer): преобразует входной текст в поток токенов. Он использует правила лексической грамматики для определения типа каждого токена и его значения.

  \item Парсер (Parser): принимает поток токенов от лексера и преобразует его в синтаксическое дерево или абстрактное синтаксическое дерево (AST) на основе синтаксической грамматики.
  
  \item Синтаксическое дерево (Parse Tree): полное дерево, отражающее все синтаксические детали входного текста. Оно включает в себя все токены и их отношения.
  
  \item Абстрактное синтаксическое дерево (AST): упрощённое представление синтаксического дерева, которое сохраняет только те детали, которые важны для дальнейшей обработки.
\end{enumerate}


Возможности ANTLR4.

\begin{enumerate}
  \item Поддержка нескольких языков: ANTLR4 поддерживает генерацию парсеров на различных языках, таких как Java, C\#, Python, JavaScript, C++, и других.
  \item Поддержка различных типов грамматик: ANTLR4 позволяет работать с контекстно-свободными грамматиками и расширениями, такими как контекстно-зависимые грамматики.
  \item Простота интеграции: Сгенерированные лексеры и парсеры можно легко интегрировать в существующие проекты, обеспечивая гибкость и масштабируемость.
  \item Оптимизация и отладка: ANTLR4 предоставляет инструменты для отладки и оптимизации грамматик и парсеров, что упрощает разработку и устранение ошибок.
  \item Гибкость в настройке: Пользователи могут настраивать лексеры и парсеры, изменяя поведение генератора кода и обработчиков ошибок.
\end{enumerate}


\section{LLVM(IR)}

\textbf{LLVM} (Low-Level Virtual Machine) \cite{llvm-ir} -- это инфраструктура для разработки компиляторов, которая предоставляет мощные инструменты для создания, оптимизации и генерации машинного кода. Основным компонентом LLVM является его промежуточное представление (Intermediate Representation, IR), которое служит мостом между высокоуровневыми языками программирования и машинным кодом.

Основные компоненты LLVM.
\begin{enumerate}
  \item LLVM IR (Intermediate Representation) -- это промежуточный язык, который компиляторы используют для описания программного кода в унифицированном формате. Он находится между высокоуровневыми языками программирования и низкоуровневыми машинными инструкциями.
  \item LLVM Core Libraries -- библиотеки предоставляют основные функции для работы с LLVM IR, включая анализ, оптимизацию и генерацию кода.
  \item LLVM Backend -- компонент отвечает за преобразование LLVM IR в машинный код для конкретной архитектуры. Он включает в себя наборы инструментов для генерации кода, оптимизации и выработки целевого кода.
  \item LLVM Frontend -- инструменты и библиотеки, которые преобразуют исходный код высокоуровневых языков в LLVM IR. Это включает в себя парсеры, лексеры и синтаксические анализаторы.
\end{enumerate}

Основные особенности LLVM IR.
\begin{enumerate}
  \item \textbf{Многоуровневая абстракция}: LLVM IR предоставляет абстракцию, которая находится между высоким уровнем языков программирования и машинным кодом. Это позволяет писать компиляторы, которые работают с одной и той же промежуточной репрезентацией, независимо от целевой платформы.
  \item \textbf{Типизация}: LLVM IR является строго типизированным. Он поддерживает различные типы данных, такие как целые числа, вещественные числа, указатели и структуры.
  \item \textbf{Модульность}: LLVM IR поддерживает модульную организацию кода, что упрощает управление зависимостями и оптимизацию.
  \item \textbf{Глобальные} и локальные переменные: Переменные в LLVM IR могут быть глобальными или локальными и могут использоваться для хранения промежуточных данных.
  \item \textbf{Функции и вызовы функций}: Функции в LLVM IR могут быть объявлены и определены, и их можно вызывать из других функций.
  \item \textbf{Управляющие конструкции}: LLVM IR поддерживает условные операторы (br для ветвления), циклы и другие управляющие конструкции.
  \item \textbf{Целевые архитектуры}: LLVM IR может быть преобразован в машинный код для различных целевых архитектур, таких как x86, ARM, MIPS и других.
  
\end{enumerate}






